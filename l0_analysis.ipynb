{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Literal, TypeAlias\n",
    "\n",
    "import circuitsvis as cv\n",
    "import einops\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import torch as t\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "from IPython.display import HTML, IFrame, clear_output, display\n",
    "from jaxtyping import Float, Int\n",
    "from openai import OpenAI\n",
    "from rich import print as rprint\n",
    "from rich.table import Table\n",
    "from sae_lens import (\n",
    "    SAE,\n",
    "    ActivationsStore,\n",
    "    HookedSAETransformer,\n",
    "    LanguageModelSAERunnerConfig,\n",
    "    SAEConfig,\n",
    "    SAETrainingRunner,\n",
    "    upload_saes_to_huggingface,\n",
    ")\n",
    "from sae_lens.toolkit.pretrained_saes_directory import get_pretrained_saes_directory\n",
    "from sae_vis import SaeVisConfig, SaeVisData, SaeVisLayoutConfig\n",
    "from tabulate import tabulate\n",
    "from torch import Tensor, nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from transformer_lens import ActivationCache, HookedTransformer\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformer_lens.utils import get_act_name, test_prompt, to_numpy\n",
    "\n",
    "device = t.device(\n",
    "    \"mps\"\n",
    "    if t.backends.mps.is_available()\n",
    "    else \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# from plotly_utils import imshow, line\n",
    "\n",
    "MAIN = __name__ == \"__main__\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:00<?, ?it/s]/home/ubuntu/.local/lib/python3.10/site-packages/sae_lens/sae.py:146: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n",
      "100%|██████████| 12/12 [00:12<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "gpt2 = HookedSAETransformer.from_pretrained(\"gpt2-small\", device=device)\n",
    "\n",
    "gpt2_saes = {\n",
    "    layer: SAE.from_pretrained(\n",
    "        release=\"gpt2-small-res-jb\",\n",
    "        sae_id=f\"blocks.{layer}.hook_resid_pre\",\n",
    "        device=str(device),\n",
    "    )[0]\n",
    "    for layer in tqdm(range(gpt2.cfg.n_layers))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseTensor:\n",
    "    \"\"\"\n",
    "    Handles 2D tensor data (assumed to be non-negative) in 2 different formats:\n",
    "        dense:  The full tensor, which contains zeros. Shape is (n1, ..., nk).\n",
    "        sparse: A tuple of nonzero values (shape (n_nonzero,)), nonzero indices (shape (n_nonzero, k)), and the shape of\n",
    "                the dense tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    sparse: tuple[Tensor, Tensor, tuple[int, ...]]\n",
    "    dense: Tensor\n",
    "\n",
    "    def __init__(self, sparse: tuple[Tensor, Tensor, tuple[int, ...]], dense: Tensor):\n",
    "        self.sparse = sparse\n",
    "        self.dense = dense\n",
    "\n",
    "    @classmethod\n",
    "    def from_dense(cls, dense: Tensor) -> \"SparseTensor\":\n",
    "        sparse = (dense[dense > 0], t.argwhere(dense > 0), tuple(dense.shape))\n",
    "        return cls(sparse, dense)\n",
    "\n",
    "    @classmethod\n",
    "    def from_sparse(\n",
    "        cls, sparse: tuple[Tensor, Tensor, tuple[int, ...]]\n",
    "    ) -> \"SparseTensor\":\n",
    "        nonzero_values, nonzero_indices, shape = sparse\n",
    "        dense = t.zeros(shape, dtype=nonzero_values.dtype, device=nonzero_values.device)\n",
    "        dense[nonzero_indices.unbind(-1)] = nonzero_values\n",
    "        return cls(sparse, dense)\n",
    "\n",
    "    @property\n",
    "    def values(self) -> Tensor:\n",
    "        return self.sparse[0].squeeze()\n",
    "\n",
    "    @property\n",
    "    def indices(self) -> Tensor:\n",
    "        return self.sparse[1].squeeze()\n",
    "\n",
    "    @property\n",
    "    def shape(self) -> tuple[int, ...]:\n",
    "        return self.sparse[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LATENT2LATENT ATTRIBUTION ###\n",
    "def latent_acts_to_later_latent_acts(\n",
    "    latent_acts_nonzero: Float[Tensor, \"nonzero_acts\"],\n",
    "    latent_acts_nonzero_inds: Int[Tensor, \"nonzero_acts n_indices\"],\n",
    "    latent_acts_shape: tuple[int, ...],\n",
    "    sae_from: SAE,\n",
    "    sae_to: SAE,\n",
    "    model: HookedSAETransformer,\n",
    "    error,\n",
    ") -> tuple[Tensor, tuple[Tensor]]:\n",
    "    \"\"\"\n",
    "    Given some latent activations for a residual stream SAE earlier in the model, computes the latent activations of a\n",
    "    later SAE. It does this by mapping the latent activations through the path SAE decoder -> intermediate model layers\n",
    "    -> later SAE encoder.\n",
    "\n",
    "    This function must input & output sparse information (i.e. nonzero values and their indices) rather than dense\n",
    "    tensors, because latent activations are sparse but jacrev() doesn't support gradients on real sparse tensors.\n",
    "    \"\"\"\n",
    "    latent_acts_from = SparseTensor.from_sparse(\n",
    "        (latent_acts_nonzero, latent_acts_nonzero_inds, latent_acts_shape)\n",
    "    ).dense\n",
    "    resid_stream_from = sae_from.decode(latent_acts_from)\n",
    "\n",
    "    resid_stream_next = model.forward(\n",
    "        resid_stream_from + error,\n",
    "        start_at_layer=sae_from.cfg.hook_layer,\n",
    "        stop_at_layer=sae_to.cfg.hook_layer,\n",
    "    )\n",
    "\n",
    "    latent_acts_next = sae_to.encode(resid_stream_next)\n",
    "\n",
    "    latent_acts_next = SparseTensor.from_dense(latent_acts_next)\n",
    "\n",
    "    return latent_acts_next.sparse[0]\n",
    "\n",
    "\n",
    "def latent_to_latent_gradients(\n",
    "    tokens: Float[Tensor, \"batch seq\"],\n",
    "    sae_from: SAE,\n",
    "    sae_to: SAE,\n",
    "    model: HookedSAETransformer,\n",
    ") -> tuple[Tensor, SparseTensor, SparseTensor, SparseTensor]:\n",
    "    \"\"\"\n",
    "    Computes the gradients between all active pairs of latents belonging to two SAEs.\n",
    "\n",
    "    Returns:\n",
    "        latent_latent_gradients:    The gradients between all active pairs of latents\n",
    "        latent_acts_prev:           The latent activations of the first SAE\n",
    "        latent_acts_next:           The latent activations of the second SAE\n",
    "        latent_acts_next_recon:     The reconstructed latent activations of the second SAE (i.e.\n",
    "                                    based on the first SAE's reconstructions)\n",
    "    \"\"\"\n",
    "    acts_prev_name = f\"{sae_from.cfg.hook_name}.hook_sae_acts_post\"\n",
    "    acts_next_name = f\"{sae_to.cfg.hook_name}.hook_sae_acts_post\"\n",
    "    sae_from_error_name = f\"{sae_from.cfg.hook_name}.hook_sae_error\"\n",
    "    sae_from.use_error_term = True\n",
    "\n",
    "    with t.no_grad():\n",
    "        # Get the true activations for both SAEs\n",
    "        _, cache = model.run_with_cache_with_saes(\n",
    "            tokens,\n",
    "            names_filter=[acts_prev_name, acts_next_name, sae_from_error_name],\n",
    "            stop_at_layer=sae_to.cfg.hook_layer + 1,\n",
    "            saes=[sae_from, sae_to],\n",
    "            remove_batch_dim=False,\n",
    "        )\n",
    "\n",
    "    latent_acts_prev = SparseTensor.from_dense(cache[acts_prev_name])\n",
    "    latent_acts_next = SparseTensor.from_dense(cache[acts_next_name])\n",
    "    sae_from_error = cache[sae_from_error_name]\n",
    "\n",
    "    latent_acts_to_later_latent_acts_and_gradients = t.func.jacrev(\n",
    "        latent_acts_to_later_latent_acts\n",
    "    )\n",
    "\n",
    "    latent_latent_gradients = latent_acts_to_later_latent_acts_and_gradients(\n",
    "        *latent_acts_prev.sparse, sae_from, sae_to, model, sae_from_error\n",
    "    )\n",
    "\n",
    "    latent_latent_attributions = einops.einsum(\n",
    "        latent_latent_gradients,\n",
    "        latent_acts_prev.sparse[0],\n",
    "        \"next_nonzero from_nonzero, from_nonzero -> next_nonzero from_nonzero\",\n",
    "    )\n",
    "\n",
    "    # Set SAE state back to default\n",
    "    sae_from.use_error_term = False\n",
    "\n",
    "    return (\n",
    "        latent_latent_gradients,\n",
    "        latent_acts_prev,\n",
    "        latent_acts_next,\n",
    "        latent_latent_attributions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 2.73k/2.73k [00:00<00:00, 228kB/s]\n",
      "Downloading readme: 100%|██████████| 7.35k/7.35k [00:00<00:00, 305kB/s]\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/sae_lens/training/activations_store.py:301: UserWarning: Dataset is not tokenized. Pre-tokenizing will improve performance and allows for more control over special tokens. See https://jbloomaus.github.io/SAELens/training_saes/#pretokenizing-datasets for more info.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Activation data sae trained on\n",
    "gpt2_act_store = ActivationsStore.from_sae(\n",
    "    model=gpt2,\n",
    "    sae=gpt2_saes[0],\n",
    "    streaming=True,\n",
    "    store_batch_size_prompts=1000,\n",
    "    n_batches_in_buffer=32,\n",
    "    device=str(device),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1217 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "batch = gpt2_act_store.get_batch_tokens()[:, :8] # truncate to 8 tokens due to cost constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 30.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.7893e-05, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Compute average latent to latent non zero attribution rate\n",
    "threshold = 1e-8\n",
    "layer_from = 0\n",
    "layer_to = 3\n",
    "non_zero_rate = 0\n",
    "for example in tqdm(batch):\n",
    "    (\n",
    "        latent_latent_gradients,\n",
    "        latent_acts_prev,\n",
    "        latent_acts_next,\n",
    "        latent_latent_attributions,\n",
    "    ) = latent_to_latent_gradients(example, gpt2_saes[layer_from], gpt2_saes[layer_to], gpt2)\n",
    "    total_pairs = gpt2_saes[layer_from].cfg.d_sae ** 2\n",
    "    non_zero_pairs = (latent_latent_attributions.abs() > threshold).sum()\n",
    "    l0_percentage = non_zero_pairs / total_pairs\n",
    "    non_zero_rate += l0_percentage\n",
    "non_zero_rate / batch.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TOKEN2LATENT GRADIENTS ###\n",
    "def tokens_to_latent_acts(\n",
    "    token_scales: Float[Tensor, \"batch seq\"],\n",
    "    tokens: Int[Tensor, \"batch seq\"],\n",
    "    sae: SAE,\n",
    "    model: HookedSAETransformer,\n",
    ") -> tuple[Tensor, tuple[Tensor]]:\n",
    "    \"\"\"\n",
    "    Given scale factors for model's embeddings (i.e. scale factors applied after we compute the sum\n",
    "    of positional and token embeddings), returns the SAE's latents.\n",
    "\n",
    "    Returns:\n",
    "        latent_acts_sparse: The SAE's latents in sparse form (i.e. the tensor of values)\n",
    "        latent_acts_dense:  The SAE's latents in dense tensor, in a length-1 tuple\n",
    "    \"\"\"\n",
    "    resid_after_emb = model(tokens, stop_at_layer=0)\n",
    "    resid_after_emb_scaled = einops.einsum(\n",
    "        resid_after_emb, token_scales, \"... s d, ... s -> ... s d\"\n",
    "    )\n",
    "    resid_before_sae = model(\n",
    "        resid_after_emb_scaled, start_at_layer=0, stop_at_layer=sae.cfg.hook_layer\n",
    "    )\n",
    "    sae_latents = SparseTensor.from_dense(sae.encode(resid_before_sae))\n",
    "    return sae_latents.sparse[0], (sae_latents.dense,)\n",
    "\n",
    "\n",
    "def token_to_latent_gradients(\n",
    "    tokens: Float[Tensor, \"batch seq\"],\n",
    "    sae: SAE,\n",
    "    model: HookedSAETransformer,\n",
    ") -> tuple[Tensor, SparseTensor]:\n",
    "    \"\"\"\n",
    "    Computes the gradients between an SAE's latents and all input tokens.\n",
    "\n",
    "    Returns:\n",
    "        token_latent_grads: The gradients between input tokens and SAE latents\n",
    "        latent_acts:        The SAE's latent activations\n",
    "    \"\"\"\n",
    "    batch, seq = tokens.shape\n",
    "    token_scales = t.ones(batch, seq, device=tokens.device)\n",
    "    token_latent_grads, (latent_acts,) = t.func.jacrev(\n",
    "        tokens_to_latent_acts, has_aux=True\n",
    "    )(token_scales, tokens, sae, model)\n",
    "    token_latent_grads = einops.rearrange(\n",
    "        token_latent_grads, \"d_sae_nonzero batch seq -> batch seq d_sae_nonzero\"\n",
    "    )\n",
    "    latent_acts = SparseTensor.from_dense(latent_acts)\n",
    "    return (token_latent_grads, latent_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:22<00:00, 45.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0054, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Compute average token to latent non zero attribution rate\n",
    "sae_layer = 3\n",
    "threshold = 1e-8\n",
    "for example in tqdm(batch):\n",
    "    (token_latent_grads, latent_acts) = token_to_latent_gradients(example.unsqueeze(0), gpt2_saes[sae_layer], gpt2)\n",
    "    total_pairs = batch.shape[-1] * gpt2_saes[3].cfg.d_sae\n",
    "    non_zero_pairs = (token_latent_grads.abs() >= threshold).sum()\n",
    "    l0_percentage = non_zero_pairs / total_pairs\n",
    "    non_zero_rate += l0_percentage\n",
    "non_zero_rate / batch.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LATENT2LOGIT ATTRIBUTIONS ###\n",
    "def latent_acts_to_logits(\n",
    "    latent_acts_nonzero: Float[Tensor, \"nonzero_acts\"],\n",
    "    latent_acts_nonzero_inds: Int[Tensor, \"nonzero_acts n_indices\"],\n",
    "    latent_acts_shape: tuple[int, ...],\n",
    "    sae: SAE,\n",
    "    model: HookedSAETransformer,\n",
    "    sae_error_term,\n",
    "    token_ids: list[int] | None = None,\n",
    ") -> tuple[Tensor, tuple[Tensor]]:\n",
    "    \"\"\"\n",
    "    Computes the logits as a downstream function of the SAE's reconstructed residual stream. If we\n",
    "    supply `token_ids`, it means we only compute & return the logits for those specified tokens.\n",
    "    \"\"\"\n",
    "    latent_acts = SparseTensor.from_sparse(\n",
    "        (latent_acts_nonzero, latent_acts_nonzero_inds, latent_acts_shape)\n",
    "    )\n",
    "    res_stream = (\n",
    "        sae.decode(latent_acts.dense) + sae_error_term\n",
    "    )  # can also do without sae error term but why? They use error term in Marks.\n",
    "    logits = model(res_stream, start_at_layer=sae.cfg.hook_layer)[0, -1]  # [d_vocab]\n",
    "    return logits[token_ids]\n",
    "\n",
    "\n",
    "def latent_to_logit_gradients(\n",
    "    tokens: Float[Tensor, \"batch seq\"],\n",
    "    sae: SAE,\n",
    "    model: HookedSAETransformer,\n",
    "    k: int | None = None,\n",
    ") -> tuple[Tensor, Tensor, Tensor, list[int] | None, SparseTensor]:\n",
    "    \"\"\"\n",
    "    Computes the gradients between active latents and some top-k set of logits (we\n",
    "    use k to avoid having to compute the gradients for all tokens).\n",
    "\n",
    "    Returns:\n",
    "        latent_logit_gradients:  The gradients between the SAE's active latents & downstream logits\n",
    "        logits:                  The model's true logits\n",
    "        logits_recon:            The model's reconstructed logits (i.e. based on SAE reconstruction)\n",
    "        token_ids:               The tokens we computed the gradients for\n",
    "        latent_acts:             The SAE's latent activations\n",
    "    \"\"\"\n",
    "    assert tokens.shape[0] == 1, \"Only supports batch size 1 for now\"\n",
    "\n",
    "    acts_hook_name = f\"{sae.cfg.hook_name}.hook_sae_acts_post\"\n",
    "    sae_error_name = f\"{sae.cfg.hook_name}.hook_sae_error\"\n",
    "    sae.use_error_term = True\n",
    "    with t.no_grad():\n",
    "        logits, cache = model.run_with_cache_with_saes(\n",
    "            tokens,\n",
    "            names_filter=[acts_hook_name, sae_error_name],\n",
    "            saes=[sae],\n",
    "            remove_batch_dim=False,\n",
    "        )\n",
    "\n",
    "    logits = logits[0, -1]\n",
    "    _, token_ids = logits.topk(k=k)\n",
    "    token_ids = token_ids.tolist()\n",
    "\n",
    "    latent_acts = cache[acts_hook_name]\n",
    "    latent_acts = SparseTensor.from_dense(latent_acts)\n",
    "    sae_error_term = cache[sae_error_name]\n",
    "\n",
    "    latent_logit_gradients = t.func.jacrev(latent_acts_to_logits)(\n",
    "        *latent_acts.sparse,\n",
    "        sae,\n",
    "        model,\n",
    "        sae_error_term,\n",
    "        token_ids,\n",
    "    )\n",
    "\n",
    "    latent_logit_attributions = latent_logit_gradients * latent_acts.sparse[0]\n",
    "    sae.use_error_term = False\n",
    "\n",
    "    return (\n",
    "        latent_logit_gradients,\n",
    "        logits,\n",
    "        token_ids,\n",
    "        latent_acts,\n",
    "        latent_logit_attributions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:41<00:00, 23.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0154, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LATENT2LOGIT L0\n",
    "k = 25\n",
    "layer = 9\n",
    "threshold = 1e-8\n",
    "non_zero_rate = 0\n",
    "for example in tqdm(batch):\n",
    "    (\n",
    "        latent_logit_grads,\n",
    "        logits,\n",
    "        token_ids,\n",
    "        latent_acts,\n",
    "        latent_logit_attributions,\n",
    "    ) = latent_to_logit_gradients(example.unsqueeze(0), sae=gpt2_saes[layer], model=gpt2, k=k)\n",
    "    total_pairs = 25 * gpt2_saes[layer].cfg.d_sae\n",
    "    non_zero_pairs = (latent_logit_attributions.abs() >= threshold).sum()\n",
    "    l0_percentage = non_zero_pairs / total_pairs\n",
    "    non_zero_rate += l0_percentage\n",
    "non_zero_rate / batch.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
